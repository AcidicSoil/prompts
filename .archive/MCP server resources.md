
Converting Markdown Prompt Repo into Local MCP Server with DAG-Aware Planning

Converting a Prompt Library into a Proactive MCP Workflow Assistant
===================================================================

Converting Prompt Playbooks into an MCP Server
----------------------------------------------

To turn a Markdown-only prompt library into an MCP server, you can expose each prompt file as an **MCP tool**. For example, the open-source _Prompts MCP Server_ demonstrates this pattern: it loads prompt templates (Markdown files with YAML frontmatter) from a `prompts/` directory and exposes operations like adding, retrieving, listing, and deleting prompts via MCP[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=Prompts%20MCP%20Server)[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=,title%2C%20description%2C%20tags%2C%20etc). In practice, you’d package your prompt files and a lightweight server program (e.g. in Node or Rust) that registers each prompt as a tool (e.g. `/planning-process` becomes a tool callable by the AI). Once installed and configured in an MCP client (like Claude Desktop or Cursor), the server advertises these prompt-tools on initialization. This approach essentially wraps your docs as a **tool library** the AI can invoke by name. It requires writing minimal glue code (to read files, handle JSON-RPC requests, etc.), and there are templates and examples available – for instance, the prompts-mcp-server above is published on NPM for quick use[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=,server)[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=Features). You would follow a similar structure: load your Markdown playbooks, perhaps parse any frontmatter (titles, descriptions, tags), and implement MCP _tool handlers_ that simply return the prompt content (or perform any slight processing needed) to the client.

Maintaining Workflow State and Context
--------------------------------------

To go beyond static prompts and make the assistant **workflow-aware**, your MCP server should maintain some **project state** across calls. MCP servers support long-lived, stateful sessions with the client – the JSON-RPC connection stays open and can carry context between requests[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=MCP%20servers%20maintain%20a%20stateful,one%20request%20to%20the%20next). This means your server can “remember” where the user is in the workflow (for example, which phase or step has been completed) and adjust the next suggestions accordingly. In fact, some MCP servers are specifically designed to keep persistent project context. For example, a _Project Context MCP Server_ can track details like the project’s name, _current phase/status_, task list, and decision history in a local store[lobehub.com](https://lobehub.com/mcp/aaronfeingold-mcp-project-context#:~:text=The%20MCP%20Project%20Context%20Server,for%20your%20development%20projects%2C%20maintaining). By exposing tools to update and query this state (e.g. `get_project_status`, `advance_phase`, or `add_task`), the server and AI together can ensure the conversation always considers what’s been done and what’s next.

Crucially, an MCP server can include a **Session Orchestrator** component that links multi-step operations together. This allows implementing a DAG or flowchart of actions as a guided sequence of tool calls. For instance, if the user’s request triggers a multi-step workflow (say Plan → Code → Test → Deploy), the orchestrator can carry information from one tool call to the next and decide when the sequence is complete[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=1,through%20multiple%20pages%20of%20results)[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=The%20Session%20Orchestrator%20is%20responsible,for). In a web-browsing MCP server example, the orchestrator tracks which page is open so that a “next page” command knows where to resume[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=1,through%20multiple%20pages%20of%20results). By analogy, your server can track which **milestone or gate** the project is at (e.g. “Scope defined”, “App scaffolded”, “Tests passing”) and only allow or suggest tools relevant to the current stage.

Using Diagrams to Plan Next Actions
-----------------------------------

Since your repository already includes a **Mermaid workflow diagram** mapping out phases P0–P9, the MCP server can leverage this as a source of truth for the process flow. In practice, you might parse the Mermaid **graph** (which is a DAG of steps and decisions) to know the dependencies and order of tasks. Some MCP servers even specialize in diagram analysis – for example, an _MCP Mermaid Server_ provides tools to **analyze an existing diagram’s structure and provide insights or improvement suggestions**[lobehub.com](https://lobehub.com/mcp/kayaozkur-mcp-server-mermaid#:~:text=%2A%20%60generate_diagram_from_code%60%20,Mermaid%20syntax%20with%20error%20details). Leveraging such capabilities, your server could include a custom tool (or integrate an existing one) to read the `workflow.mmd` Mermaid file and determine “what comes next.” For instance, if the project is in phase P3 (Data & Auth), a diagram analysis tool could find the next node after P3 and suggest or auto-trigger the commands under P4 (Frontend UX). Even without a dedicated diagram parser, you can encode the workflow logic in a simple state machine or lookup table: e.g. after **Scope Gate** is passed, the server knows the next phase is App Scaffold (P2) and could notify the user or proactively call the `/scaffold-fullstack` prompt. The key is that by **modeling the workflow** (via the Mermaid diagram or an equivalent DAG in code), the server can drive the assistant to follow a structured game plan rather than just reacting blindly. This yields a more _systematic, proactive assistant_ that guides the developer through each stage in order.

Enabling Autonomous Step Execution
----------------------------------

Finally, to have the MCP server _autonomously advance implementation steps_, you can take advantage of MCP’s support for **agent-initiated actions**. Unlike a stateless API, MCP’s persistent connection allows the server to send **notifications or prompts back to the client** asynchronously[github.com](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/102#:~:text=MCP%20is%20currently%20a%20stateful,us%20to%20support%20behaviors%20like). In practical terms, once the server detects that a certain condition is met (say, the “Test Gate” milestone achieved all green tests), it could emit a notification or result indicating “Gate cleared – ready to proceed to next phase.” Modern AI hosts (Claude Code, Cursor, etc.) are built to handle such server-initiated messages, enabling what the MCP spec calls _agentic workflows_[github.com](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/102#:~:text=MCP%20is%20currently%20a%20stateful,us%20to%20support%20behaviors%20like). With this, your MCP server doesn’t have to passively wait for the user to invoke the next slash command; it can proactively suggest or even trigger the next tool.

For example, you might implement a tool like `next_step_recommendation` that returns the next recommended command based on the stored state (phase, pending tasks, any “Gate” criteria). The assistant could call this at the end of each phase, effectively asking “what should I do next?”, and your server would respond with something like: _“Proceed to P5: run /e2e-runner-setup to set up end-to-end testing”_. Alternatively, the server can be configured to push a notification to the client as soon as a phase’s exit criteria are met. Because the MCP server can maintain a _live context_ and even initiate calls, it serves as the **planner/foreman** in the workflow: tracking progress, updating the state store after each tool action, and guiding the AI on what tool or prompt to invoke next.

By drawing on existing patterns – a prompts library server for the base commands[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=Prompts%20MCP%20Server), a context-tracking layer for project state[lobehub.com](https://lobehub.com/mcp/aaronfeingold-mcp-project-context#:~:text=The%20MCP%20Project%20Context%20Server,for%20your%20development%20projects%2C%20maintaining), diagram-driven logic for sequencing[lobehub.com](https://lobehub.com/mcp/kayaozkur-mcp-server-mermaid#:~:text=%2A%20%60generate_diagram_from_code%60%20,Mermaid%20syntax%20with%20error%20details), and MCP’s event capabilities for proactivity[github.com](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/102#:~:text=MCP%20is%20currently%20a%20stateful,us%20to%20support%20behaviors%20like) – you can transform your docs-only playbook into an intelligent MCP server. Such a server will not only respond to slash commands but also **act as a workflow orchestrator**, interpreting the project’s design map (your Mermaid flowchart) and proactively advancing the development process step by step. This ensures the AI assistant always knows _where you are_ in the project and what to do next, essentially becoming a hands-on project co-pilot rather than just a passive text generator.

References and Examples
-----------------------

- _Prompts MCP Server_ – Open-source MCP server that exposes Markdown prompt templates as tools[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=Prompts%20MCP%20Server)[github.com](https://github.com/tanker327/prompts-mcp-server#:~:text=,title%2C%20description%2C%20tags%2C%20etc). Helpful as a blueprint for wrapping a docs catalog into a running MCP service.

- _Project Context MCP Server_ – Example MCP server that **maintains project state** (current phase, tasks, decisions) between sessions[lobehub.com](https://lobehub.com/mcp/aaronfeingold-mcp-project-context#:~:text=The%20MCP%20Project%20Context%20Server,for%20your%20development%20projects%2C%20maintaining), illustrating how to persist and query workflow context.

- _MCP Mermaid Server_ – Demonstrates tools for **interpreting and generating flowcharts**; e.g. it can analyze a Mermaid diagram’s structure and suggest improvements[lobehub.com](https://lobehub.com/mcp/kayaozkur-mcp-server-mermaid#:~:text=%2A%20%60generate_diagram_from_code%60%20,Mermaid%20syntax%20with%20error%20details), useful for building diagram-aware assistants.

- _MCP Protocol Discussions_ – MCP is stateful and supports **server-initiated messages** (notifications, streaming) to enable agent-driven workflows[github.com](https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/102#:~:text=MCP%20is%20currently%20a%20stateful,us%20to%20support%20behaviors%20like). This is the basis for making the assistant proactive in executing a sequence of steps.

- _MCP Architecture Guides_ – Overviews of MCP server components and session orchestration, showing how multi-step actions can be handled internally[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=1,through%20multiple%20pages%20of%20results)[workos.com](https://workos.com/blog/how-mcp-servers-work#:~:text=The%20Session%20Orchestrator%20is%20responsible,for) (e.g. sequential tool calls managed by the server). These can guide the design of your “DAG-aware” planner logic within the server.
