# Overview

prompts-mcp-server is a production-grade Model Context Protocol (MCP) server that exposes Markdown prompt files as tools, encodes a directed acyclic graph (DAG) for workflow gating, and ships a planner that proposes next calls based on state and artifacts. It targets AI tool integrators, LLM application engineers, and platform teams who need deterministic, inspectable prompt tooling with progress gating. It solves unstructured prompt distribution, lack of execution order, and brittle state tracking by providing dynamic tool surfacing, DAG-aware planning, file-based artifacts, and safety guards such as payload caps and redacted logging.

# Core Features

## 1) Dynamic Prompt Tools

* What: Expose each prompt in resources/prompts/\*.md as an MCP tool with generated schemas.
* Why: Standardize prompt access and enable client-side orchestration via MCP.
* How: Parse prompts.meta.yaml; register tools with input/output schemas; handler returns prompt content with payload capping.
* Acceptance criteria:

  * Given a prompt entry in prompts.meta.yaml when the server starts then a tool with matching id is registered.
  * Given a tool invocation when the prompt file exists then the response contains the Markdown content and a rendered footer.
  * Given a prompt larger than 1 MB when served then the response is truncated with an ellipsis note.

## 2) Resource Exposure

* What: Serve each prompt Markdown as a file:// resource with mimeType text/markdown.
* Why: Let clients preview prompts without executing tools.
* How: On startup, load metadata and register resources with absolute file URIs and capped text.
* Acceptance criteria:

  * Given a prompt with resource path when the server starts then a resource is listed with a file:// URI and human name.
  * Given an oversized resource when read then the text is capped to \~1 MB with a truncation note.

## 3) Planner: suggest\_next\_calls

* What: Rank next runnable tools based on DAG dependencies and required artifacts.
* Why: Enforce correct sequencing and reduce operator error.
* How: Load default-graph.json and .mcp/state.json; compute readiness; sort by phase order.
* Acceptance criteria:

  * Given an empty state when suggest\_next\_calls runs then it returns discover\_research as the first candidate.
  * Given discover\_research completed with research\_summary artifact when suggest\_next\_calls runs then define\_prd appears in ranked results.
  * Given a node with unmet artifact requirements when suggest\_next\_calls runs then that node is not returned.

## 4) State Management and Gating

* What: Persist tool completions, outputs, and artifact paths; gate progress on subsequent steps.
* Why: Provide deterministic, idempotent progress tracking.
* How: StateStore writes .mcp/state.json via atomic rename; recordCompletion merges artifacts; planner reads it.
* Acceptance criteria:

  * Given a completed tool when advance\_state is called then .mcp/state.json exists and includes timestamp, outputs, and artifacts.
  * Given concurrent save attempts when save runs then the final file is valid JSON due to write-to-temp then rename.

## 5) advance\_state tool

* What: Mark a tool complete and record outputs and artifacts.
* Why: Move the workflow forward and unlock dependent nodes.
* How: Expose advance\_state MCP tool; handler calls StateStore.recordCompletion.
* Acceptance criteria:

  * Given valid input with id when calling advance\_state then it returns ok: true and a statePath under .mcp/.
  * Given artifacts in input when calling advance\_state then state.artifacts includes each key with provided deterministic path.

## 6) Interop export\_task\_list

* What: Emit a compact task list for external planners.
* Why: Allow task-master-ai or other systems to visualize DAG.
* How: Read prompts.meta.yaml and map to id, title, dependsOn, status: pending.
* Acceptance criteria:

  * Given metadata when export\_task\_list runs then tasks\[] contains all prompt ids with correct dependencies.

## 7) Safety Controls

* What: Enforce payload cap, redact secrets in logs, and avoid external HTTP by default.
* Why: Reduce leakage risk and control resource usage.
* How: capPayload truncates strings at \~1 MB; logging.redactEnv hides keys matching /(key|secret|token)/i; rate limiter stub disables external calls by default.
* Acceptance criteria:

  * Given environment variables with secret-like names when server\_start logs then log output shows \[redacted] values.
  * Given a response body exceeding cap when returned then it includes a “\[truncated N bytes]” trailer.

## 8) Rate Limiting Utility

* What: Provide a token-bucket for outbound HTTP stubbing.
* Why: Bound future external integrations and tests.
* How: TokenBucket with capacity, refill per second, and take() with simple wait.
* Acceptance criteria:

  * Given zero tokens when take(1) is called then it waits approximately 1/refillPerSec seconds before granting.
  * Given capacity C when take(C) then tokens decrease to zero and recover over time.

## 9) Server Bootstrap and Transport

* What: Start MCP server on stdio with graceful shutdown.
* Why: Enable use in MCP Inspector and Claude Desktop.
* How: StdioServerTransport; SIGINT/SIGTERM handlers; register tools and resources on startup.
* Acceptance criteria:

  * Given server start when inspected then name=prompts-mcp-server and version=0.1.0 are reported.
  * Given SIGINT when received then process exits after logging server\_stop.

# User Experience

* Personas:

  * Tool Integrator: wires MCP servers into clients and automation.
  * LLM Engineer: iterates on prompts and wants repeatable gating.
  * QA Engineer: validates sequencing and state transitions.
  * PM/Tech Lead: reviews PRD and architecture artifacts as resources.
* Key flows:

  * Setup: install deps, build, start server; connect via MCP Inspector or Claude Desktop using provided config.
  * Manual run: call discover\_research → advance\_state(research\_summary) → define\_prd → advance\_state(prd).
  * Planner-led: call suggest\_next\_calls each step; only ready nodes appear until artifacts exist.
  * Artifact review: open file:// resources to view prompt content.
* UI/UX considerations:

  * JSON tool I/O with minimal required fields.
  * Stable ids matched to prompts.meta.yaml and default-graph.json.
  * Human-friendly titles for resources.
* Accessibility considerations:

  * Text-based interfaces only; ensure log output is machine-parseable NDJSON.
  * No color reliance; timestamps in ISO 8601.

# Technical Architecture

* System components:

  * MCP Server (stdio): process bootstrap, tool and resource registries, transport wiring.
  * Prompt Registry: loads prompts.meta.yaml and Markdown files.
  * Planner: reads graph JSON and state; computes readiness and ranking.
  * State Store: file-backed JSON with atomic persistence.
  * Utilities: logging with redaction, payload capping, token-bucket rate limiter.
* Data models:

  * GraphDef { version, nodes\[] }, NodeDef { id, title, phase, dependsOn?, produces?, requiresArtifacts?, exitCriteria? }.
  * ProjectState { version, completed { id → { at, outputs?, artifacts? } }, artifacts { key → path } }.
  * PromptMeta { id, title, phase, description?, dependsOn?, inputs?, outputs?, artifacts?, resource? }.
* APIs and integrations:

  * MCP tool interfaces: suggest\_next\_calls, advance\_state, export\_task\_list, plus dynamic prompt tools.
  * Resources: file:// URIs for prompt Markdown.
  * Clients: MCP Inspector and Claude Desktop via stdio.
* Infrastructure requirements:

  * Runtime: Node.js ≥ 20, TypeScript build to dist/.
  * Filesystem access with permission to create .mcp/ directories and write state.json.
  * No database; no external HTTP by default.
* Non-functional requirements:

  * Reliability: atomic writes for state; server survives restarts with intact state.
  * Performance: register ≥100 prompts within 1 second on a typical laptop; suggest\_next\_calls in <50 ms on graphs ≤100 nodes.
  * Security: never log secret values; cap outputs; no network egress by default; optional gating warning on direct tool calls.
  * Consistency: deterministic ordering of suggestions by phase then id; stable ids across restarts.
  * Portability: runs on macOS, Linux, and Windows with Node ≥20; uses path.join and file:// URIs.
  * Observability: structured JSON logs with ts, level, event, msg, correlation\_id.
  * Testability: unit tests for planner gating; enable vitest execution headless.
  * Maintainability: single-responsibility modules; config via prompts.meta.yaml and default-graph.json.
  * Scalability: supports single-process usage; graph and prompts load proportional to file count.
* Cross-platform strategy:

  * Optional: file:// resource preview depends on client support; fallback is tool execution returning prompt text.
  * Optional: POSIX signals on Windows may differ; fallback uses manual process termination supported by client.
  * Optional: path separators differ; implementation uses Node path utilities to normalize.
* Security and privacy considerations:

  * Redact environment secrets in logs using /(key|secret|token)/i.
  * Cap payloads to \~1 MB to avoid large data leaks.
  * Planner gating discourages out-of-order execution; direct calls log a warning.
  * Artifacts are file paths only; contents are not ingested by default.

# Development Roadmap

* MVP requirements with acceptance criteria:

  * Dynamic Prompt Tools, Resource Exposure, Planner suggest\_next\_calls, advance\_state, export\_task\_list, State Store with atomic writes, Safety Controls, Server Bootstrap and Transport. Acceptance criteria as defined in Core Features.
* Future enhancements with acceptance criteria:

  * External HTTP enablement:

    * How: flag to allow outbound calls guarded by TokenBucket.
    * Criteria: Given ALLOW\_HTTP=1 when making N requests then rate limiter enforces capacity and refill.
  * Schema validation for inputs/outputs:

    * Criteria: Given invalid tool input when invoked then server returns structured error with path and reason.
  * Editable DAG and hot-reload:

    * Criteria: Given modified default-graph.json when server receives SIGHUP or hot-reload command then new graph is used without crashing.
  * Metrics and health endpoints (optional transport):

    * Criteria: Given metrics enabled when tools execute then counters increase and can be scraped or logged.
  * Encrypted state at rest:

    * Criteria: Given encryption key when saving then state file is unreadable without the key and loads successfully with it.
  * Workspace scaffolder and CI stub generation:

    * Criteria: Given implement\_stub run then repo scaffold exists and build passes in CI.
  * Multi-tenant workspaces:

    * Criteria: Given two roots when operating then their .mcp/state.json files are isolated.
  * Config reload for prompts.meta.yaml:

    * Criteria: Given added prompt file when reloaded then a new tool and resource appear.

# Logical Dependency Chain

1. Bootstrap server and logging.
2. Load prompts.meta.yaml and register resources.
3. Register dynamic prompt tools with schemas.
4. Load DAG and state store.
5. Implement suggest\_next\_calls planner.
6. Implement advance\_state persistence.
7. Implement export\_task\_list interop.
8. Enforce payload capping and redacted logging.
9. Provide token-bucket utility for future HTTP.
10. Add tests for planner gating and state write behavior.

# Risks and Mitigations

* Protocol drift in MCP:

  * Likelihood: Medium. Impact: High.
  * Mitigation: Pin @modelcontextprotocol/sdk version; add compatibility tests.
* Filesystem permissions and path issues:

  * Likelihood: Medium. Impact: Medium.
  * Mitigation: Create directories recursively; normalize paths; document Windows file:// nuances; fallback to tool text when resource preview fails.
* State corruption on crash:

  * Likelihood: Low. Impact: High.
  * Mitigation: Atomic write via temp file then rename; validate JSON before replace; keep last-known-good backup.
* Oversized payload performance hit:

  * Likelihood: Medium. Impact: Medium.
  * Mitigation: Cap at \~1 MB; stream or paginate in future.
* Direct tool invocation bypassing planner:

  * Likelihood: Medium. Impact: Medium.
  * Mitigation: Log warnings; rely on clients to call planner; document gating.
* Secret leakage in logs:

  * Likelihood: Low. Impact: High.
  * Mitigation: Redaction regex; avoid logging env by default.
* Cross-platform signal handling:

  * Likelihood: Medium. Impact: Low.
  * Mitigation: Provide manual shutdown guidance; ensure graceful exit on supported signals.
* Client dependency risk:

  * Likelihood: Medium. Impact: Medium.
  * Mitigation: Keep stdio transport generic; test with MCP Inspector and Claude Desktop.
* Data privacy of artifact paths:

  * Likelihood: Low. Impact: Medium.
  * Mitigation: Store paths only; recommend non-sensitive directories; allow configurable root.

# Appendix

* Assumptions:

  * Operators run Node.js ≥ 20 and have filesystem write access.
  * Clients support MCP stdio and can consume file:// resources.
  * No external HTTP calls are required for MVP.
  * Single-process usage is sufficient; no clustering required.
  * Artifacts are deterministic file paths controlled by the operator.
  * Environment variables may contain secrets and must not be logged in cleartext.
* Research findings and references:

  * “OpenAI MCP docs — Create a server” link noted in README.
  * “Model Context Protocol docs” link noted in README.
* Technical specifications and terms glossary:

  * MCP: protocol for tool/resource servers over transports like stdio.
  * DAG: directed acyclic graph defining tool dependencies.
  * Artifact: file path recorded in state to gate subsequent steps.
  * NDJSON: newline-delimited JSON logging format.
  * Token bucket: rate limiting algorithm with capacity and refill rate.
